# CRM B2Dev - Scraping Google Maps

## ğŸš¨ RÃˆGLES CRITIQUES
- TOUJOURS vÃ©rifier les doublons avant insertion en BDD (tÃ©lÃ©phone, email, siteWeb)
- GÃ©rer les doublons **pendant le scraping** ET **pendant l'import Excel**
- JAMAIS scraper plus de 100 prospects par ville
- Ne scraper QUE les entreprises sans site valide ou avec site obsolÃ¨te
- Les tÃ©lÃ©phones doivent Ãªtre formatÃ©s sans espaces : "0612345678"
- Tous les commentaires et messages en FRANÃ‡AIS

---

## ğŸ“‹ Ã€ PROPOS DU PROJET

CRM pour identifier et contacter des artisans/PME avec des sites web obsolÃ¨tes ou inexistants.
L'objectif est de leur proposer les services de crÃ©ation de sites web de B2Dev.

**Utilisateurs :**
- Amaury : gestion commerciale et relation client
- Partenaire technique : dÃ©veloppement des sites

**Stack technique :**
- Next.js 14 (App Router)
- TypeScript (strict mode)
- PostgreSQL via Supabase
- Prisma ORM
- Playwright pour scraping Google Maps
- Tailwind CSS
- xlsx pour import/export Excel

---

## ğŸ” AUTHENTIFICATION

**SystÃ¨me : Next-Auth avec emails autorisÃ©s**

### Fonctionnement
- Liste d'emails autorisÃ©s dans le code (AUTHORIZED_EMAILS)
- Connexion via Google OAuth uniquement
- Si email pas dans la liste â†’ AccÃ¨s refusÃ©
- Si email autorisÃ© â†’ AccÃ¨s complet au CRM

### Emails AutorisÃ©s Actuels
- amaury.allemand@example.com (Amaury - Commercial)
- partenaire.technique@example.com (Partenaire - Dev)
- *(Ã  complÃ©ter avec vrais emails)*

### Pages Publiques
- `/login` : Page de connexion Google
- `/api/auth/*` : Routes Next-Auth

### Pages ProtÃ©gÃ©es (toutes les autres)
- `/scraping` : Scraping Google Maps
- `/leads` : Gestion des leads
- `/api/*` : Toutes les API routes

### Configuration
- Provider : Google OAuth
- Variables d'env nÃ©cessaires :
  - `GOOGLE_CLIENT_ID`
  - `GOOGLE_CLIENT_SECRET`
  - `NEXTAUTH_SECRET`
  - `NEXTAUTH_URL`

### Ajout/Retrait de Membres
- Modifier le tableau `AUTHORIZED_EMAILS` dans `lib/auth-config.ts`
- RedÃ©ployer l'application

---

## ğŸ—ï¸ STRUCTURE DU PROJET
```
app/
â”œâ”€â”€ page.tsx                    # Redirection vers /scraping
â”œâ”€â”€ scraping/
â”‚   â””â”€â”€ page.tsx                # PAGE SCRAPING avec formulaire
â”œâ”€â”€ leads/
â”‚   â”œâ”€â”€ page.tsx                # PAGE LEADS avec tableau + import Excel
â”‚   â””â”€â”€ [id]/page.tsx           # DÃ©tail d'un lead
â””â”€â”€ api/
    â”œâ”€â”€ scrape/route.ts         # POST: Lancer le scraping
    â”œâ”€â”€ leads/
    â”‚   â”œâ”€â”€ route.ts            # GET: liste leads, POST: crÃ©er lead
    â”‚   â”œâ”€â”€ [id]/route.ts       # GET/PUT/DELETE: lead individuel
    â”‚   â””â”€â”€ import/route.ts     # POST: Import fichier Excel
    â””â”€â”€ export/route.ts         # GET: Export Excel

lib/
â”œâ”€â”€ scraper.ts                  # Logique Playwright pour Google Maps
â”œâ”€â”€ site-validator.ts           # Validation qualitÃ© site web
â”œâ”€â”€ database.ts                 # Fonctions Prisma rÃ©utilisables
â”œâ”€â”€ excel-parser.ts             # Parse fichiers Excel uploadÃ©s
â”œâ”€â”€ validators.ts               # Validation et nettoyage des donnÃ©es
â””â”€â”€ types.ts                    # Types TypeScript partagÃ©s

prisma/
â”œâ”€â”€ schema.prisma               # SchÃ©ma de la base de donnÃ©es
â””â”€â”€ migrations/                 # Historique des migrations

components/
â”œâ”€â”€ ScrapingForm.tsx            # Formulaire scraping (mÃ©tier + villes)
â”œâ”€â”€ LeadsTable.tsx              # Tableau des leads avec filtres
â”œâ”€â”€ LeadRow.tsx                 # Ligne de tableau lead
â”œâ”€â”€ ImportExcel.tsx             # Upload + import Excel
â””â”€â”€ StatusSelect.tsx            # Select pour statut lead
```

---

## ğŸ¯ PAGE SCRAPING

### Configuration Anti-Ban Optimale

**DÃ©lais (millisecondes) :**
- `PAGE_LOAD`: 3000ms - AprÃ¨s chargement Google Maps
- `AFTER_SEARCH`: 3000ms - AprÃ¨s lancement recherche
- `BETWEEN_SCROLLS`: 2000ms - Entre chaque scroll
- `BETWEEN_CITIES`: 2500ms - Entre chaque ville (randomisÃ© 2000-3000ms)
- `TIMEOUT`: 30000ms - Timeout max par page

**Rate Limiting :**
- 2-3 secondes entre chaque ville (RANDOMISÃ‰ pour Ã©viter pattern bot)
- 2 secondes entre chaque scroll
- Randomisation : +/- 500ms sur tous les dÃ©lais

**Techniques Anti-DÃ©tection :**
- âœ… Playwright Stealth mode activÃ© (masque les signaux bot)
- âœ… User-Agent rÃ©aliste : Chrome/Mac OS X
- âœ… Mode headless (plus rapide, moins dÃ©tectable)
- âœ… DÃ©lais randomisÃ©s (Ã©viter patterns fixes)
- âœ… Pas de connexion compte Google
- âœ… Viewport rÃ©aliste : 1920x1080

**Limites Quotidiennes RecommandÃ©es :**
- Maximum 20-30 villes par jour (safe)
- Maximum 100 prospects par ville
- Ã‰viter de scraper la mÃªme ville plusieurs fois par jour

### FonctionnalitÃ©s de l'Interface

- Zone de texte : "Type d'entreprise" (ex: "plombier", "Ã©lectricien")
- Zone de texte : "Villes" (ex: "Paris, Lyon, Marseille")
- Bouton "Lancer le scraping"
- Affichage temps rÃ©el des prospects trouvÃ©s
- Afficher une barre de chargement
- Compteur par ville (max 100)

### CritÃ¨res de SÃ©lection (Motif SÃ©lection)

1. âŒ **Pas de site web** â†’ "Pas de site"
2. âŒ **Site sur annuaire** (PagesJaunes, Yelp, etc.) â†’ "Site annuaire"
3. âŒ **Site rÃ©seaux sociaux uniquement** (Facebook, Instagram) â†’ "RÃ©seaux sociaux uniquement"
4. âŒ **Site plateforme** (Travaux.com, HomeAdvisor, etc.) â†’ "Site plateforme"
5. âŒ **Site non mobile-friendly** â†’ "Non responsive"
6. âŒ **Site obsolÃ¨te** (avant 2018) â†’ "Site obsolÃ¨te"

### Sites Ã  Rejeter (ne PAS scraper)

- Sites normaux et rÃ©cents (aprÃ¨s 2018)
- Sites responsive et bien conÃ§us
- Sites e-commerce professionnels

---

## ğŸ¯ PAGE LEADS

### Colonnes du Tableau

| Colonne | Type | Description |
|---------|------|-------------|
| Nom | Texte | Nom de l'entreprise |
| TÃ©lÃ©phone | Texte | Format: 0612345678 |
| Site Web | Texte | URL complÃ¨te ou "Aucun" |
| Adresse | Texte | Adresse complÃ¨te |
| Ville | Texte | Ville (utilisÃ©e pour filtre) |
| Motif SÃ©lection | Texte | Pourquoi on l'a sÃ©lectionnÃ© |
| Statut | Select | Ã‰tat du lead (voir ci-dessous) |
| Note | Texte long | Notes libres |

### Statuts Possibles (dans cet ordre)

1. ğŸ” A contacter
2. ğŸ“… RDV maquette
3. ğŸ“„ Envoie Devis
4. â³ Attente d'acompte
5. ğŸ’° Acompte payÃ©
6. ğŸ¨ RDV de mis projet
7. ğŸ“ RDV de fin de projet + Formation
8. âœ… Finis
9. ğŸ›‘ Perdu

### FonctionnalitÃ©s

- Tableau avec tri et filtres (par ville, statut, motif)
- Bouton "Importer Excel" â†’ Upload fichier .xlsx
- Bouton "Exporter Excel" â†’ TÃ©lÃ©charge tous les leads
- Clic sur ligne â†’ Ouvre dÃ©tail du lead
- Modification inline du statut
- DÃ©tection automatique des doublons lors de l'import

---

## ğŸ—ƒï¸ BASE DE DONNÃ‰ES

### SchÃ©ma Prisma
```prisma
model Lead {
  id              String   @id @default(uuid())
  nom             String
  telephone       String?  @unique
  email           String?  @unique
  siteWeb         String?  @unique
  adresse         String?
  ville           String
  codePostal      String?
  metier          String   // Ex: "plombier"
  motifSelection  String   // Ex: "Pas de site", "Site obsolÃ¨te"
  statut          String   @default("A contacter")
  note            String?  @db.Text
  noteGoogle      Float?   // Note Google (1-5)
  nombreAvis      Int?     // Nombre d'avis Google
  createdAt       DateTime @default(now())
  updatedAt       DateTime @updatedAt

  @@index([ville])
  @@index([statut])
  @@index([metier])
}
```

---

## ğŸ” LOGIQUE DE SCRAPING

### Ã‰tapes du Scraping

1. Parse les villes (split par virgule)
2. Pour chaque ville :
   - Recherche Google Maps : "{mÃ©tier} {ville}"
   - Scroll pour charger rÃ©sultats
   - **Limite : 100 prospects max par ville**
   - Extraire : nom, tÃ©lÃ©phone, site, adresse, note, avis

3. **Validation du site web :**
   - Si pas de site â†’ âœ… Ajouter (motif: "Pas de site")
   - Si site annuaire (pagesjaunes.fr, yelp.fr) â†’ âœ… Ajouter (motif: "Site annuaire")
   - Si rÃ©seaux sociaux uniquement (facebook.com, instagram.com) â†’ âœ… Ajouter (motif: "RÃ©seaux sociaux uniquement")
   - Si site plateforme (travaux.com, homeadvisor.fr) â†’ âœ… Ajouter (motif: "Site plateforme")
   - Si site existe et valide â†’ VÃ©rifier responsive + date
     - Non responsive â†’ âœ… Ajouter (motif: "Non responsive")
     - Date < 2018 â†’ âœ… Ajouter (motif: "Site obsolÃ¨te")
     - Sinon â†’ âŒ Rejeter (bon site)

4. **VÃ©rification doublons en temps rÃ©el** (avant ajout en BDD)
   - Check tÃ©lÃ©phone, email, siteWeb dans la BDD
   - Si existe dÃ©jÃ  â†’ Skip

5. Insertion en BDD

### Configuration Playwright

- Mode headless par dÃ©faut
- Timeout : 30 secondes/page
- Rate limiting : 2 secondes entre requÃªtes
- User-agent : navigateur classique

---

## ğŸ“¥ IMPORT EXCEL

### Format Attendu

Fichier comme `prospects_plombier_*.xlsx` :

| Nom | TÃ©lÃ©phone | Site Web | Adresse | Ville | Motif SÃ©lection | Statut | Note |
|-----|-----------|----------|---------|-------|-----------------|--------|------|
| ... | ... | ... | ... | ... | ... | ... | ... |

### Logique d'Import

1. Upload fichier .xlsx
2. Parse avec bibliothÃ¨que `xlsx`
3. Pour chaque ligne :
   - Nettoyer les donnÃ©es (tÃ©lÃ©phone sans espaces, etc.)
   - **VÃ©rifier doublons** (tÃ©lÃ©phone, email, siteWeb)
   - Si doublon â†’ Skip avec log
   - Si nouveau â†’ InsÃ©rer en BDD
4. Retourner rÃ©sumÃ© : "X leads importÃ©s, Y doublons ignorÃ©s"

---

## ğŸ“¤ EXPORT EXCEL

### FonctionnalitÃ©

- Bouton "Exporter vers Excel"
- GÃ©nÃ¨re fichier : `leads_export_{date}.xlsx`
- Contient toutes les colonnes du tableau
- Format identique aux imports (rÃ©utilisable)

---

## âœ… WORKFLOW DE DÃ‰VELOPPEMENT

### ğŸ“ Avant de Commencer une Phase

1. Claude Code lit attentivement la phase dans `plan.md`
2. Claude Code propose un plan d'action dÃ©taillÃ© avec :
   - Liste des fichiers Ã  crÃ©er/modifier
   - Ordre des Ã©tapes d'implÃ©mentation
   - DÃ©pendances techniques nÃ©cessaires
3. Amaury valide ou demande des ajustements

### ğŸ› ï¸ Pendant l'ImplÃ©mentation

1. Claude Code implÃ©mente Ã©tape par Ã©tape avec explications
2. Commentaires en franÃ§ais dans le code pour expliquer la logique
3. Gestion d'erreur robuste avec try/catch et messages clairs
4. Logs dÃ©taillÃ©s pour debugging

### âœ… Ã€ la Fin de Chaque Phase (OBLIGATOIRE)

**Claude Code DOIT rÃ©diger un rapport complet dans `PROGRESS.md` qui contient :**

#### 1ï¸âƒ£ Explication de la Phase
- Quel est l'objectif de cette phase ?
- Pourquoi cette phase existe dans le projet global ?
- Quelle valeur mÃ©tier elle apporte ?

#### 2ï¸âƒ£ RÃ©alisations ConcrÃ¨tes
- **Liste TOUS les fichiers crÃ©Ã©s** avec leur rÃ´le prÃ©cis
- **Liste TOUS les fichiers modifiÃ©s** avec ce qui a changÃ© et pourquoi
- **FonctionnalitÃ©s implÃ©mentÃ©es** avec dÃ©tails techniques

#### 3ï¸âƒ£ IntÃ©gration dans le Projet
- Comment cette phase dÃ©pend des phases prÃ©cÃ©dentes ?
- Qu'est-ce qu'elle prÃ©pare pour les phases suivantes ?
- Comment elle s'intÃ¨gre dans l'architecture globale ?

#### 4ï¸âƒ£ Guide de Test Complet
- **Commandes Ã  exÃ©cuter** (npm run dev, prisma studio, etc.)
- **ScÃ©narios de test prÃ©cis** :
  - Actions Ã  faire (ex: "Cliquer sur X, remplir Y avec Z")
  - RÃ©sultats attendus (ex: "La page doit afficher...")
  - Cas limites Ã  tester (donnÃ©es manquantes, erreurs, etc.)
- **Checklist de validation** : critÃ¨res prÃ©cis pour dire "cette phase fonctionne"

#### 5ï¸âƒ£ Points d'Attention âš ï¸
- **ProblÃ¨mes non rÃ©solus** : bugs connus, limitations temporaires
- **Failles de sÃ©curitÃ© potentielles** : ce qui pourrait Ãªtre exploitÃ©
- **Warnings techniques** : deprecations, dÃ©pendances Ã  surveiller
- **Limitations connues** : ce qui n'est pas encore gÃ©rÃ©

#### 6ï¸âƒ£ DÃ©cisions Techniques
- Choix importants faits pendant la phase
- Pourquoi ces choix (alternatives envisagÃ©es)
- Impact sur les phases futures

**Format :** Utiliser le template fourni dans `PROGRESS.md`

### ğŸ§ª Tests par Amaury

1. Amaury suit le guide de test fourni dans PROGRESS.md
2. Amaury valide que tous les critÃ¨res de la checklist sont OK
3. Amaury signale tout problÃ¨me rencontrÃ©

### ğŸ“ Validation Avant Phase Suivante

- âœ… Tous les tests passent
- âœ… Aucun point d'attention bloquant
- âœ… PROGRESS.md Ã  jour avec rapport complet
- âœ… Amaury donne son feu vert explicite

**âš ï¸ IMPORTANT :** Ne JAMAIS passer Ã  la phase suivante sans avoir :
1. RÃ©digÃ© le rapport complet dans PROGRESS.md
2. Fourni un guide de test clair
3. ListÃ© tous les points d'attention
4. Obtenu la validation d'Amaury

### ğŸ’¾ Commit

- Message descriptif en franÃ§ais
- RÃ©fÃ©rence Ã  la phase (ex: "Phase 3: Validation sites web - implÃ©mentation")

---

## ğŸ¯ CONVENTIONS DE CODE

- TypeScript strict mode activÃ©
- Async/await pour toutes les opÃ©rations asynchrones
- Nommage : 
  - camelCase pour variables et fonctions
  - PascalCase pour composants React et types
  - kebab-case pour fichiers
- Toujours utiliser try/catch pour les opÃ©rations Playwright et Prisma
- Gestion d'erreur : retourner des objets `{ success: boolean, data?: T, error?: string }`
- Commentaires en franÃ§ais dans le code

---

## ğŸ“Š QUALITÃ‰ DU CODE

- Toujours vÃ©rifier les types TypeScript (pas de `any`)
- Tester les edge cases (pas de tÃ©lÃ©phone, pas de site, erreurs rÃ©seau)
- GÃ©rer les erreurs proprement avec messages clairs en franÃ§ais
- Logs dÃ©taillÃ©s pour debugging
- Interface utilisateur intuitive et responsive

---

## âš¡ COMMANDES IMPORTANTES
```bash
npm run dev              # Serveur dev (http://localhost:3000)
npm run build            # Build production
npx prisma migrate dev   # CrÃ©er une migration
npx prisma studio        # Interface visuelle BDD
npx prisma generate      # RÃ©gÃ©nÃ©rer le client Prisma
```

---

## ğŸš€ DÃ‰PLOIEMENT (plus tard)

- Vercel pour le frontend + API Routes
- Supabase pour PostgreSQL (free tier : 500MB)
- Variables d'environnement via `.env.local` (JAMAIS commit le .env)

---

## ğŸ’¡ NOTES IMPORTANTES

- Le projet remplace un workflow Excel manuel
- Objectif : centraliser prospects + Ã©viter doublons
- Amaury gÃ¨re le commercial, partenaire gÃ¨re le technique
- PrivilÃ©gier la simplicitÃ© et la clartÃ© du code
- Interface doit Ãªtre rapide et intuitive pour usage quotidien